# HÆ¯á»šNG DáºªN Sá»¬ Dá»¤NG NHANH - LAB 02

## ğŸ“Œ Tá»•ng quan

Pipeline Ä‘Ã£ sáºµn sÃ ng sá»­ dá»¥ng! Táº¥t cáº£ tests Ä‘Ã£ pass. DÆ°á»›i Ä‘Ã¢y lÃ  hÆ°á»›ng dáº«n tá»«ng bÆ°á»›c.

## âœ… ÄÃ£ hoÃ n thÃ nh

- [x] LaTeX Parser (multi-file gathering)
- [x] Hierarchy Builder (tree structure)
- [x] LaTeX Cleaner (standardization)
- [x] BibTeX Processor (extraction & deduplication)
- [x] ML Feature Extraction
- [x] Reference Matching Model
- [x] Test suite (4/4 tests passed âœ…)

## ğŸ“‹ BÆ°á»›c tiáº¿p theo

### BÆ¯á»šC 1: Cháº¡y Pipeline xá»­ lÃ½ dá»¯ liá»‡u

```powershell
cd Source
python main.py
```

**Output**: Xá»­ lÃ½ táº¥t cáº£ publications trong `sample/` vÃ  táº¡o files output trong `<MSSV>/`

**Files Ä‘Æ°á»£c táº¡o cho má»—i publication:**
- âœ“ `metadata.json` (copied)
- âœ“ `references.json` (copied)
- âœ“ `refs.bib` (deduplicated BibTeX)
- âœ“ `hierarchy.json` (tree structure)
- â³ `pred.json` (sáº½ táº¡o sau khi train ML)

### BÆ¯á»šC 2: Manual Labeling (Cáº¦N LÃ€M THá»¦ CÃ”NG)

**YÃªu cáº§u:**
- GÃ¡n nhÃ£n cho **Ã­t nháº¥t 5 publications**
- Tá»•ng cá»™ng **Ã­t nháº¥t 20 cáº·p** (bib_key, arxiv_id)

**CÃ¡ch lÃ m:**

1. Chá»n 5 publications tá»« output directory
2. Má»Ÿ `refs.bib` vÃ  `references.json` cá»§a má»—i publication
3. Matching cÃ¡c BibTeX entries vá»›i arXiv IDs
4. Táº¡o file `manual_labels.json`:

```json
{
  "2310-15395": {
    "Krnjaic:2023odw": "2307.00041",
    "Caputo:2020msf": "2012.09179",
    "Boddy:2022knd": "2207.XXXXX"
  },
  "2310-15396": {
    "Smith:2020": "2301.XXXXX",
    ...
  }
}
```

**Tips Ä‘á»ƒ matching:**
- TÃ¬m arXiv ID trong BibTeX entry (field `eprint`)
- So khá»›p title giá»¯a BibTeX vÃ  references.json
- So khá»›p authors vÃ  year
- DÃ¹ng Google Scholar Ä‘á»ƒ xÃ¡c nháº­n

### BÆ¯á»šC 3: Auto Labeling & Data Splitting

Sau khi cÃ³ `manual_labels.json`, cháº¡y script auto labeling:

```python
# Táº¡o file auto_label.py trong Source/
from reference_matching import ReferenceMatchingModel
from pathlib import Path
import json

# Load manual labels
with open('manual_labels.json') as f:
    manual_labels = json.load(f)

# TODO: Implement auto labeling using heuristics
# - Regex Ä‘á»ƒ tÃ¬m arXiv ID trong BibTeX
# - Title similarity > 0.9
# - Author overlap > 0.5

# TODO: Split data
# - 5 pubs manual â†’ 1 test, 1 valid, 3 train
# - Remaining pubs â†’ split by ratio
```

### BÆ¯á»šC 4: Train ML Model

```python
# train_model.py
from reference_matching import ReferenceMatchingModel, compute_mrr
import json

# Load training data
# ... (load BibTeX entries and references)

# Create feature vectors
model = ReferenceMatchingModel()
X_train, y_train = model.create_training_data(training_examples)

# Train
model.train(X_train, y_train)

# Save model
import pickle
with open('trained_model.pkl', 'wb') as f:
    pickle.dump(model, f)
```

### BÆ¯á»šC 5: Generate Predictions

```python
# predict.py
from reference_matching import ReferenceMatchingModel
import pickle
import json

# Load model
with open('trained_model.pkl', 'rb') as f:
    model = pickle.load(f)

# For each test publication
for pub_id in test_pubs:
    # Load refs.bib and references.json
    # ...
    
    predictions = {}
    for bib_key, bib_entry in bib_entries.items():
        # Get top-5 candidates
        top5 = model.rank_candidates(bib_entry, references, top_k=5)
        predictions[bib_key] = [arxiv_id for arxiv_id, score in top5]
    
    # Save pred.json
    pred_data = {
        "partition": "test",  # or "train", "valid"
        "groundtruth": groundtruth_dict,
        "prediction": predictions
    }
    
    with open(f'{pub_id}/pred.json', 'w') as f:
        json.dump(pred_data, f, indent=2)
```

### BÆ¯á»šC 6: Evaluate MRR

```python
from reference_matching import compute_mrr

# Load test predictions
mrr_scores = []
for pub_id in test_pubs:
    with open(f'{pub_id}/pred.json') as f:
        data = json.load(f)
    
    mrr = compute_mrr(data['prediction'], data['groundtruth'])
    mrr_scores.append(mrr)

average_mrr = sum(mrr_scores) / len(mrr_scores)
print(f"Test MRR: {average_mrr:.4f}")
```

### BÆ¯á»šC 7: Viáº¿t BÃ¡o cÃ¡o

DÃ¹ng template `REPORT_TEMPLATE.md` vÃ  Ä‘iá»n:

1. **Thá»‘ng kÃª xá»­ lÃ½ dá»¯ liá»‡u**
   - Sá»‘ publications, versions, elements
   - Tá»· lá»‡ deduplication
   
2. **Feature engineering**
   - Giáº£i thÃ­ch tá»«ng feature
   - Feature importance tá»« model
   
3. **ML Results**
   - MRR scores (train, valid, test)
   - Error analysis
   - Example predictions

4. **Screenshots**
   - Hierarchy structure
   - Feature distributions
   - Confusion matrix (náº¿u cÃ³)

### BÆ¯á»šC 8: Táº¡o Video Demo (240-300s)

**Ná»™i dung video:**
1. Giá»›i thiá»‡u project (30s)
2. Cháº¡y pipeline (60s)
3. Giáº£i thÃ­ch hierarchy.json (60s)
4. Giáº£i thÃ­ch ML pipeline (60s)
5. Káº¿t quáº£ vÃ  MRR (30s)

## ğŸ”§ Troubleshooting

### Lá»—i: "No main file found"

**NguyÃªn nhÃ¢n**: Folder khÃ´ng cÃ³ file .tex vá»›i `\begin{document}`
**Giáº£i phÃ¡p**: Kiá»ƒm tra láº¡i folder structure

### Lá»—i: "Unicode decode error"

**NguyÃªn nhÃ¢n**: File cÃ³ encoding Ä‘áº·c biá»‡t
**Giáº£i phÃ¡p**: ÄÃ£ xá»­ lÃ½ tá»± Ä‘á»™ng vá»›i multiple encodings

### Lá»—i: "Model not trained"

**NguyÃªn nhÃ¢n**: ChÆ°a cÃ³ training data
**Giáº£i phÃ¡p**: Sá»­ dá»¥ng heuristic scoring thay vÃ¬ ML model

## ğŸ“Š Kiá»ƒm tra káº¿t quáº£

```python
# Verify output
from pathlib import Path
import json

output_dir = Path('../<MSSV>')

for pub_dir in output_dir.iterdir():
    if not pub_dir.is_dir():
        continue
    
    print(f"\nPublication: {pub_dir.name}")
    
    # Check required files
    for filename in ['metadata.json', 'references.json', 'refs.bib', 'hierarchy.json']:
        filepath = pub_dir / filename
        if filepath.exists():
            print(f"  âœ“ {filename}")
            if filename == 'hierarchy.json':
                data = json.load(open(filepath))
                print(f"    Elements: {len(data['elements'])}")
                print(f"    Versions: {len(data['hierarchy'])}")
        else:
            print(f"  âœ— {filename} MISSING")
```

## ğŸ“¦ Chuáº©n bá»‹ ná»™p bÃ i

1. **Cáº¥u trÃºc folder:**
```
<MSSV>.zip
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ *.py (all Python files)
â”‚   â””â”€â”€ requirements.txt
â”œâ”€â”€ <MSSV>/
â”‚   â”œâ”€â”€ 2310-15395/
â”‚   â”‚   â”œâ”€â”€ metadata.json
â”‚   â”‚   â”œâ”€â”€ references.json
â”‚   â”‚   â”œâ”€â”€ refs.bib
â”‚   â”‚   â”œâ”€â”€ hierarchy.json
â”‚   â”‚   â””â”€â”€ pred.json (if in train/valid/test)
â”‚   â””â”€â”€ ...
â”œâ”€â”€ README.md
â”œâ”€â”€ Report.pdf
â””â”€â”€ [Link to video demo]
```

2. **Checklist trÆ°á»›c khi ná»™p:**
   - [ ] Táº¥t cáº£ publications Ä‘Ã£ xá»­ lÃ½
   - [ ] Manual labels cho â‰¥5 pubs, â‰¥20 pairs
   - [ ] Auto labels cho â‰¥10% remaining
   - [ ] pred.json cho train/valid/test pubs
   - [ ] MRR scores Ä‘Æ°á»£c tÃ­nh
   - [ ] Report hoÃ n chá»‰nh vá»›i figures
   - [ ] Video demo uploaded
   - [ ] README.md cÃ³ hÆ°á»›ng dáº«n cháº¡y

## ğŸ’¡ Tips quan trá»ng

1. **Backup thÆ°á»ng xuyÃªn**: Dá»¯ liá»‡u xá»­ lÃ½ máº¥t nhiá»u thá»i gian
2. **Version control**: DÃ¹ng git Ä‘á»ƒ track changes
3. **Test tá»«ng bÆ°á»›c**: KhÃ´ng cháº¡y toÃ n bá»™ pipeline má»™t lÃºc
4. **Log errors**: Ghi láº¡i cÃ¡c publications failed Ä‘á»ƒ debug
5. **Validate output**: Kiá»ƒm tra format JSON trÆ°á»›c khi ná»™p

## ğŸ¯ Má»¥c tiÃªu cuá»‘i cÃ¹ng

- [ ] Process all publications successfully
- [ ] MRR score > 0.5 (good target)
- [ ] Complete report with analysis
- [ ] Clear video demonstration
- [ ] Well-documented code

## ğŸ“ LiÃªn há»‡

Náº¿u cÃ³ váº¥n Ä‘á» vá»›i code, check:
1. README.md trong Source/
2. Test output tá»« test_pipeline.py
3. Error messages trong console

Good luck! ğŸš€
